Thank you for your helpful comments. The two specific recommendations
were addressed by adding more discussion of constructiveness and
logical correctness (mostly in section 2) and elaborating on the
differences between our semantics and other semantics in the related
work.

We also annotated the reviews to show how we responded to each
comment. Thank you again for such helpful and thoughtful reviews.

Review #191A
===========================================================================


> Paper summary
> -------------
>
> Esterel is a language used in safety-critical embedded systems like
> airplanes and nuclear power plants. It has a unique model, wherein
> multiple agents working concurrently do all of their work (sending
> signals on special "signal variables", writing or reading to shared
> variables, running commands in some host language, etc.) in a single
> coordinated *instant*.
>
> The existing execution models for Esterel come in two flavors:
> denotational in the domain of circuits or operational in the domain
> of whole programs. This paper introduces a new model, using small
> step semantics to give meaning to program fragments. The authors
> must work carefully to faithfully reproduce Esterel's idiosyncratic
> and subtle semantics. Much of the paper focuses on the reduction
> semantics to coordinate an instant, which involves a complicated
> dynamic analysis called the $\mathsf{Can}$ predicate. The
> $\mathsf{Can}$ predicate determines which signals may or may not be
> sent, which determines what happens during an instant. The analysis
> is quite subtle: once $\mathsf{Can}$ observes that a certain signal
> variable can or can't be sent in a given instant, the program will
> prune paths arbitrarily far away in the program. Numerous examples
> of this "action at a distance" are early in the paper.
>
> The authors derive an equational theory between Esterel terms by
> taking an appropriate closure over the reduction semantics: a
> relation $\equiv_e$ is defined as the reflexive, well-formed
> symmetric, transitive closure over the compatible (i.e., reduce in
> any context) closure of the reduction semantics. They prove a
> variety of program identities using their equational theory. The
> equational theory is not complete in that their proofs have
> preconditions that, strictly speaking, are unnecessary but are
> required by technicalities in their semantics.
>
> Finally, they have tested their semantics by fixing a reduction
> strategy and comparing to HipHop, a JavaScript-hosted Esterel
> implementation, and also by randomly generating Esterel terms and
> comparing them to other implementations (HipHop, Esterel v5, and the
> "constructive operational semantics" of Berry [2002] and
> Potop-Butucaru and de Simone [2004]). They have found five bugs:
> four in HipHop and one in Esterel v5.
>
> Strengths
> ---------
> Esterel is an interesting language of critical importance that is
> not well known in the POPL community. This paper, at a minimum, will
> raise interest in Esterel.
>
> Explanations are lucid and the writing is clear.
>
> The formalism is easy to follow, which is a feat for such a subtle
> subject.
>
> The semantics are novel and interesting; I imagine they will form
> the basis of interesting study to come.
>
> Weaknesses
> ----------
>
> The discussion of *logical correctness* and *constructivity* could
> be clarified.

Revised.

> It's not obvious that this semantics helps existing or new users of
> Esterel, whether due to lack of strength or because equational
> reasoning isn't what's needed.

We improved the related work to address this and also explain more
clearly how our calculus can do things other semantics cannot in
smaller ways in various places.

> Comments for author
> -------------------
> I've set my expertise as Y because I am an experienced semanticist,
> have worked with concurrency and signal-based programming, and am
> lightly familiar with Esterel, though I'd properly be a Z for
> Esterel itself, having never read the papers.
>
> This paper is a lovely and clear introduction to Esterel, and the
> semantics are novel and interesting. I hope that readers will be
> inspired by Esterel's notion of *instant* and use it in other
> venues. I imagine that this semantics will help with that process. I
> think this paper represents a lovely bit of work that will hopefully
> influence language design in years to come, even if its semantics
> aren't the final word. Nice work!
>
> I've listed two weaknesses above, but I think they are very modest
> ones. I'll discuss them a bit, as I think it may improve the paper.
>
> You mention logical correctness and constructiveness early in the
> paper (L71-72), but it may be worth noting that these are
> essentially Esterel-specific notions. It's never completely clear
> what they *are* as notions. Are they correctness criteria in that
> programs failing either one should never be allowed to run?
> Discussion later on seems to indicate that breaking constructiveness
> isn't catastrophic (L858), but it's said that such programs "have no
> meaning" (L224). Are these properties truly illegal and should
> (ideally) be statically disallowed but have the moral force of a
> type error at runtime? Or are they more like unspecified and
> undefined behavior in C, where the program is 'bad' and can behave
> in strange ways, but not *illegal*? As a non-expert in Esterel, some
> more clarity here would be helpful. The fact that constructivity is
> a subset of logical correctness (L262) should be emphasized earlier.

Revised.

> More technically, I can't help but wonder if certain tweaks to
> $\mathsf{Can}$ or the semantics might help weed out these
> non-constructive programs. Perhaps another analysis that looks at
> the program graph and identifies circularities that $\mathsf{Can}$
> doesn't in its ordinary course of business? I suspect the
> $\mathsf{Can}-\Theta$ algorithm could be simplified in a similar
> way: look at the program graph, sort topologically (breaking cycles
> arbitrarily), and then prune signals in that order. While it may not
> necessarily avoid exponential behavior, it might offer some speedup
> by giving a better order in which to consider signals.

These sound like interesting ideas and may already be being pursued by
Esterel compilers, but are more than we can do in the present work.

> I'm concerned that the equational reasoning you're able to provide
> isn't local enough. All of your rules require signals to be locally
> defined, which means that one can only reason about tiny fragments
> of a program. What does it look like to reason about communication
> with the outside world? To be clear, I think the paper stands well
> on its own even if you can't handle such examples, but it would be
> helpful to readers to really understand what the limits are.

We added more discussion at the end of 8 about general patterns where
our calculus is unable to prove certain classes of equivalences.

> Some of the ideas and terminology around signals is reminiscent of
> FRP. It may be helpful to some readers to explain the difference in
> related work (or even earlier).

We see a much deeper connection between Lustre and other sibling
languages of Esterel that are more dataflow focused and FRP than we do
with Esterel (that is more control focused), and so were unable to
find how to draw a helpful connection here.

> If you find yourself tight for space, less information on the
> "standard reduction rules" would be fine.
>
> ## Minutae
>
> L224 "even though they would [have meaning?] in a traditional
> programming"

Revised.

> L571-578 This record notation is hardly unique to TAPL. I imagine
> that Pierce borrowed it from ML, which presumably borrowed it from
> C, which borrowed it from who knows where.

We clarified why we cite Pierce (we tried many different ones,
actually, (including the above and python and others) and found this
one to be the best one for our purposes, but yes, the differences are
minor).

> L700 The correct binding rule for $\mathsf{par}$ is *quite*
> subtle. It may be worth explicitly calling out that $\mathbf{x}$
> ranges only over sequential variables. Similarly, it may be worth
> mentioning on L708 the restriction on $\mathsf{loop}$ is designed to
> ban reincarnated variables.

We have improved this section of the paper based on this comment (and
others).

> L762 It would be helpful to back reference the $\lfloor \theta^c
> \rfloor$ notation here or in the paragraph from L808-814.

Fixed.

> L899 Do you mean $\subset$ or $\in$ for $q \subset \mathbf{done}$?

Fixed.

> L1004 "had failed [to find?] what"

Fixed.

> It may just be my printer, but several parts of the paper came out
> unnecessarily bolded, as though bold had spilled over from keywords.
>
> Questions for authorsâ€™ response
> ---------------------------------
> Your calculus accepts some non-constructive programs, equating them
> to constructive ones. Does your calculus reject all logically
> incorrect programs?
>
> Why doesn't $\mathsf{Eval}$ produce not just a set of signals, but a
> set of host language expressions to evaluate for the shared and
> sequential variables? Are these other notions of output considered
> when determining whether two programs are equivalent?

We expanded the former section 6 (now section 3.4) to explain this.

> Why do you require $\vdash_{\mathsf{CB}} \mathbf{p}$ in the symmetry
> rule of $\equiv_e$?

We added a note about this.

> Is $\equiv_e$ a congruence, i.e., if $p_1 \equiv_e p_2$ and $q_1
> \equiv_e q_2$, is it the case that $(\mathsf{par} ~ p_1 ~ q_1)
> \equiv_e (\mathsf{par} ~ p_2 ~ q_2)$? It certainly *ought* to be the
> case (by transitivity and compatible stepping)... but the semantics
> are subtle enough that I'm not 100% confident.

We state more clearly that it is a congruence.

> Is $\rightharpoonup$ meant to be strongly normalizing? (The rule
> $[\mathbf{par-swap}]$ breaks normalization but not confluence.) What
> about $\longrightarrow$? Are there program behaviors besides getting
> stuck or reducing to a $\mathbf{complete}$ state?

It is and we now say so (and point to the proof in the Agda).

> Can you prove Theorem 8.5 with $q \in \mathbf{complete}$, not just
> in $\mathbf{done}$? If not, what breaks?

We added a note saying we could if we had the lifting rule.

>
> Review #191B
> ===========================================================================
>
> Weaknesses
> ----------
> * The semantics are not used for very much, so there is only a
>   little the evidence that this semantics is better than other
>   existing ones.
>
>
> Comments for author
> -------------------
> The examples throughout made it easy to follow the paper, even
> though this reviewer has not looked at Esterel before.
>
> It is a shame that the $\rho$ expressions get in the way of the
> general optimisation for 8.6, since it is the main technical gadget
> that makes the semantics work. The paper would be stronger with the
> lifting rule alluded to on page 19 included, but it is proper that
> the author(s) leave it out since the theorems about it are not
> proved.
>
> Questions for authorsâ€™ response
> ---------------------------------
> Would it be feasible to complete the proofs and add the lifting rule
> from page 19 before the camera ready deadline?
>
> Review #191C
> ===========================================================================
>
> Strengths
> ---------
>
> Very clear English; first machine-checked semantics proof of the
> Esterel language so far as I know.
>
> Weaknesses
> ----------
>
> Very little effort is spent explaining how and why these semantics
> differ from the three or four other semantics that already exist for
> the language.
>
> Comments for author
> -------------------
> First, I'd stress at the beginning of the paper that you've coded
> and machine-checked your semantics, which I believe is a first for
> Esterel (at least, you're one of very few to have done this). It
> really strengthens your contribution.

We added a brief note.

> Second, given that there are already a plethora of existing
> semantics for Esterel (which you cite), readers should be far more
> interested in how your approach differs from existing ones, rather
> than the mechanics of yours. You address this just a little in
> section 11, but it's too little, too late. Surely there's room for a
> discussion of some interesting contrasts between how you handle
> shared variables in your semantics versus how other semantics do (or
> does not) handle them.

Beyond the high-level (calculus vs circuits etc), we've also added
some discussion to section 3.3 (in the new numbers) that describes how
signals work in our calculus, as that is one of the most interesting
technical differences.

> Along these line, you claim the big improvement for your semantics
> is that it's a calculus and thus allows for equational reasoning,
> but I didn't clearly see any example of how this worked or the
> benefits of it. Yes, this may be ignorance on my part, but I'd
> really appreciate seeing a "here's an example of the sort of
> question our semantics can answer that all the others can't."

We have added a note to the beginning of the related work section
along these lines.

> Review #191D
> ===========================================================================
>
> Paper summary
> -------------
>
> This works proposes a subset of the Esterel programming language,
> named Kernel Esterel, and defines an evaluation semantics for it. It
> is notable because the Esterel language is useful and strange, and
> this is the first syntax-based operational semantics done using
> simple tools that are familiar to the POPL community.
>
> The main technical contribution of this work is a non-deterministic,
> goes-under-arbitrary contexts reduction relation, which (1)
> naturally extends into an equivalence relation, its
> symmetric-transitive closure, which can be used for program
> reasoning, and (2) determines a (partial) evaluation function, whose
> result is the (provably unique) normal form obtained from the
> relation -- when it exists. The authors also use the equivalence
> relation to justify some program equivalences of interest. The
> metatheory of these relations and equivalences is formalized in
> Agda.
>
> Then the authors propose a particular, more deterministic strategy
> to be able to actually compute some of the normal forms of this
> calculus (it only gets stuck on "non-constructive programs", a
> well-understood difficult fragment that is also rejected by other
> Esterel implementations), for which they propose a Redex model,
> which was used to check (by fuzzing / random testing) that the
> semantics correspond to other existing semantics or implementations
> of Esterel, and found a couple subtle bugs in existing
> implementations.
>
> Strengths
> ---------
> I believe this work is interesting and valuable for both the POPL and
> the Esterel communities.
>
> The evaluation is very strong: Agda proofs of the meta-theory,
> fuzzing-based checking of the language specification compared to
> other implementations.
>
> I firmly recommend accepting the submission.
>
> Weaknesses
> ----------
> The paper is dry to read for non-Esterel people because it uses all
> of its space budget to explain the semantics of Esterel, with no
> explanations of why the features of Esterel are this way, or why the
> semantics was designed in that way.

We have attempted to improve the paper along these lines (mostly in
section 2) based on this feedback.

> The reduction strategy (the restricted, more computable relation) is
> interesting but under-developed. One should at least prove that it
> is valid with respect to the calculus.

We are not able to get this done (yet). We agree it is important.

> The authors were not able to restrict the calculus to get stuck on
> non-constructive terms. (And thus be complete with respect to a weak
> reduction.)
>
> Comments for author
> -------------------
> I have some high-level criticisms, then more minor comments.
>
> ### Dry presentation
>
> I think you would widen considerably the audience of your paper by
> reclaiming some space to discuss the design *reasons* for the
> features whose semantics are so delicate/subtle. "Deterministic
> concurrency" is something easily understood as desirable by anyone
> in the PL community, but what about this weird business of blocking
> code fragments waiting on signals emitted in the same instant? What
> is `suspend` for? (I found no answer to this `suspend` question and
> ignored this construct for the whole paper.) Why are loops
> restricted to be this way? What is this weird failure model with De
> Bruijn indices used as exceptions?
>
> Right now the paper may be a great fit for Esterel experts who are
> already at home with all these features. I'm not, and it made for a
> very dry read. The paper is of course of most value to Esterel
> experts, so it makes sense to pack content for them, but it could
> also be used by students who are just learning about the language,
> or even by PL people looking for a recent reference to a real-world
> use-case for this somewhat less-standard "Evaluation relation"
> approach of Felleisen.
>
> One thing that may help in this direction is to show at least one
> example of a program that is not a synthetic construction to show
> some weird use-case, but something that has some spirit of a useful
> problem domain left in it. It could be very simple. The "book
> chapter" version of the Potop-Bucaru and de Simone paper that you
> refer to starts with a simple "suspendable and killable reactive
> loop" example that would do.
>
> Another thing that may help (I don't know if you can do both within
> space constraints) is to give some general intuition for the
> justification of the language features that you introduce and whose
> complexity we have to bear through the paper. Page 5, I wrote in my
> margin:
>
> How do those features help Esterel's problem domain?
>
> I believe that I need no convincing about shared and sequential
> variables, nothing/pause, seq/par. But why are signals, with all the
> complexity they introduce, an important feature for the problem
> domain? Do they help modeling embedded programs? Do they help
> compositionality? Why is it important to be able to locally declare
> those signals? What is `suspend` for?  I could reconstruct answers
> to some of those questions, but some explanations wouldn't have
> hurt.
>
> Finally, if you want to add examples and/or explanations, then you
> need to take some content out -- move it to an appendix. With the
> current article structure that you have chosen, my vote would go for
> the figures 25, 26 and 27. They take more than two full pages, they
> don't add much intuitions besides the calculus that we have
> understood in detail and your textual explanations of how you
> defined the strategy (the one rule that I liked is the new [absence]
> rule, the rest is just noise to me). At this point of the paper, we
> are already too exhausted to spend the mental budget on a whole new
> family of judgments anyway.

We have added some information about design rationale about each of
the points listed as questions in the first paragraph above, when the
constructs are introduced in section 2.

We agree that a more in depth discussion of these design points would
be great, but we were not able to do it for this version of the paper.

> ### Article structure
>
> In several places I was unhappy with the article structure, the
> order in which you chose to introduce the content. The problem is
> always the same, you introduce important ideas too late in the
> paper. I had been wondering about them and worried by not hearing
> about them for a few pages already.
>
> More specifically:
>
> - Don't assume that everyone is familiar with Felleisen's beloved
>   "Evaluation function" approach. As far as I know, his book is the
>   only introductory PL book in use these days to introduce this
>   concept, and most people (students or non-students) only ever read
>   one such book. At the beginning of your paper you should describe
>   the different pieces you will present (reduction rules, the
>   derived congruence, Eval, and finally the strategy) from a
>   high-level perspective: how they conspire to give a useful
>   specification for a programming language.


We reorganized the paper to make room for an introduction to the
calculus itself and included some discussion along these lines there
(the new section 3 is a combination of the old sections 3, 4, 5, and
6).

> - Esterel is peculiar in that there is a "one instant" semantic,
>   which you spend most of your effort on, and a "run repeatedly"
>   semantics, and the relation between the two is non-trivial (unlike
>   the relation between `->` and `->*` in a small-step operational
>   semantics). The latter is what matters to interpret practical
>   programs in the way that people care about, and the way it works
>   is important to understand some of your reduction rules and
>   examples. I shouldn't have to wait until page 16 to realize that
>   you plan to define it formally. Page 14, I wrote in the margin
>
>   > How do we go from the end of an instant to the beginning of the next?
>
>   (My guess at the time was: `(loop E[pause] q) -> E[loop q]`)
>
>   I believe that the three-quarter-turns-arrow relation should be
>   defined much earlier, for example at the end of Section 2,
>   together with only a high-level view of the reduction relation
>   (only the judgment shape, for example), and the concept of
>   complete environment.
>

The new introduction to the calculus explains the high-level structure
and gives a roadmap. New readers will not have to guess about these
things.

> - I kept wondering whether you admit alpha-renaming of signal names
>   (this is not obvious given the comparison to wires and the
>   discussions of what happens when the same signal name is bound
>   twice locally) until you pointed out that you do on page 15.

We have rewritten section 4 (new numbers; it was 7 before) in a way
that we hope helps with this.

> - You shouldn't wait until Section 9 on page 20 to mention that you
>   have an executable reduction that captures a subset of your
>   evaluation function, and how this executable reduction was
>   designed. Its existence should be mentioned earlier in the paper.
>
>  (In fact, lines 969-978 provides the best explanation in your paper
>   of the "calculus => evaluation function" approach to operational
>   semantics.)

We added a note in the roadmap about this.

> ### Minor comments
>
> Page 1:
>
> > Existing semantics of these languages
>
> Which languages? Only one language (Esterel) was mentioned so far.

Fixed.

> ----
>
> Page 5:
>
> Idle curiosity: when reading your explanation for Figure 7, I
> wondered whether it is correct, when faced with a `(present S p q)`
> test, to optimistically assume either `present` or `absent`, and
> then backtrack if the execution is later found inconsistent -- if
> neither work, then `unknown` it is. (Does the subset of terms where
> this work coincide with constructiveness?)

We have added a note using exactly this idea in section 2 where we
introduce constructiveness.

> ----
>
> Page 7:
>
> Your explanation of shared variables is mildly contradictory. You
> first say "the [shared] variables may not be read until it can no
> longer be written in the current instant", and then "multiple writes
> are allowed but only with an assoc./commut. operation"; intuitively
> one think of updating a variable with an operation to be a read
> followed by a write. Maybe you could just write "As an exception to
> the no-write-after-read rule, " at the beginning of the "Multiple
> writes" paragraph to acknowledge the tension.

Fixed.

> ----
>
> In the beginning of Section 3, I asked myself why you chose to have
> environments within expressions (note: this corresponds to what we
> call "explicit substitutions") instead of an abstract-machine
> calculus with only a global environment.
>
> The answer is that the in-expression form allows local/equational
> reasoning. This should be pointed out explicitly in the paper,
> instead of assuming that people are familiar with the design choices
> of the "calculus" approach. (I think you could still have an
> abstract machine, and then reason with "under any environment, ...",
> but your current choice is also reasonable.)

Improved.

> ----
>
> Note 4: at the time of reading this note, I wrote in my margin:
>
> > Aren't all shared variables local? How do you observe them?
>
> I understand now that an Esterel "component" may have both free
> signals and free shared variables, but note that this is
> incompatible with your current definition of the Eval function,
> where only present signals are observable. (Of course it would be
> easy to also observe free variables.)

This note now seems unhelpful. We have deleted it.

> ----
>
> Page 8:
>
> Your notation for environment domain restriction is very heavy -- it's
> not a notation, it's a heavy composition of existing/standard
> notations. Why not just use `Theta\{S}`?

Fixed.

> ----
>
> Page 9:
>
> I'm not particularly impressed with the choice of a thick-leftarrow
> to represent the associative/commutative operation in your syntax,
> because it looks like a comparison operator to me. Have you
> considered just using `+=` ?

We changed it to use +=.

> ----
>
> Storing the value introduced by `(shared s := e p)` as `old` makes
> no sense to me. It was certain it was a typo when I read the
> figure. Otherwise, `(shared s := e1 (+= s e2))` would set `s` to
> `e2` instead of `e1 + e2`, which makes no sense whatsoever.
>
> On page 21 you remark that you started with `new` here and found a
> discrepancy with other semantics so switched back to `old`. Two
> remarks on this remark:
>
> - I still suspect that it is simply a bug in the other semantics,
>   rather than in your own. If it isn't, maybe you could show a
>   plausible example that explains this extremely peculiar design
>   choice.

We expanded the explanation of the rules in section 2 to address this.

> - Your comment on "a year of debugging, hand inspection and theorem
>   proving" sounds like music to the ears of Redex people, but it is
>   somewhat trite given that the theorems you mention in the paper
>   would not prevent you from using a completely different semantics
>   for many of the language operators, as long as it preserves
>   determinism. `(if x p q)` could have its two arms swapped and you
>   wouldn't notice. (More generally it's clear that if you wrote your
>   implementation with a specification in mind that is both
>   sensible/reasonable and different from someone else's, no amount
>   of checking of your implementation alone will detect it.)

We've stated this more simply.

> ----
>
> Page 10: when reading about shared and sequential variables, I was
> reminded of the work on deterministic concurrency at the language
> level (for example: the Oz model of concurrent unification
> variables, and the LVar model of monotonic writes *and*
> reads). Clearly the Esterel community has thought more than most
> about the interaction of deterministic concurrent state and
> conrol-flow (Signals), but I would be curious to know if some
> aspects of the specification could be done in terms of
> existing/separate deterministic-concurrency device; using stock
> LVars instead of shared variable would strictly increase
> expressiveness.
>
> I think there is a missed opportunity for discussing possible
> connections in the Related Work. (Again, your paper is mainly meant
> for Esterel experts, but a POPL submission is also an opportunity to
> connect with a larger audience whose interest can be piqued by
> connecting to other works in their own communities.)

We see a clear connection to LVars and added a citation to help in
section 2. The connection to Oz's model is less clear to us, so we
refrain from adding one, although recommendations on specific papers
and how they connect remain welcome.

> ----
>
> Pages 11 and 12:
>
> The syntax for `Can-Theta` is terrible. The first time I saw it, I
> thought that this weirdly-typeset `Theta` was a LaTeX-typesetting
> typo for an ordinary (bold) Theta variable. Grammars have both
> syntactic categories ("type", "term") and metavariables ("tau",
> "e"), those two things are not the same, and in notations you should
> use something looking like the syntactic category, not the
> metavariable -- if you are not satisfied with just syntactic
> overloading of `Can(p, Theta)`, `Can(Theta, Theta')`. What about
> `Can_{Env}(Theta, Theta')` for example?

We changed it to Can_{\rho}, in the hope that reusing a relevant
terminal symbol will be evocative, not confusing. (We think it looks
much better and appreciate the suggestion.)

> I found the figure defininig of Can-Theta fairly confusing to read
> (I generally read the figure *before* the informal explanation, and
> it's better when the figure can be pleasantly understood on its
> own). Here would be a proposed reformulation:
>
>    Can_Env(rho \emptyset. p, Theta')
>    = Can(p, Theta')
>
>    Can_Env(rho Theta+{S -> known}.p, Theta')
>    = Can_Env(rho Theta.p, Theta'+{S -> known})
>
>    Can_Env(rho Theta+{S -> unknown}.p, Theta')
>    = if S \in Can_S(unknown)
>      then Can_S(unknown)
>      else Can_S(absent)
>
>      where Can_S(status) = Can_Env(rho Theta.p, Theta'+{S -> status})
>
> Note that if you had a readable definition for Can-Theta, you
> wouldn't be worried about reusing it for `signal` (instead of
> `signal` being a necessary didactic step), and could
> simplify/factorize figure 14:
>
>    Can(signal S p, Theta) = Can-Theta(rho {S -> unknown}. p, Theta)
>
> which is in line with the reduction rule for `signal` -- really
> syntactic sugar for a singleton `rho`.
>
> Nitpick: in the syntax `rho Theta. p`, the environment is before (to
> the left of) the term that it scopes over. It would thus be more
> consistent to use `Can(Theta, p)` and `Can_Env(Theta, rho
> Theta'.p)`, as `Theta` is a more global environment that scopes over
> the other argument.

We decided to leave this alone because it is the order in other
presentations of `Can` use and because the function is defined by
cases on the first argument with the current order.

> ----
>
> > Constructing a record uses curly braces surrounding ...
>
> I'm not sure we need a whole paragraph to explain this fairly
> obvious notation. (Not if it competes for space with clearer
> high-level explanation of Esterel's design or of your specification
> approach.)

We streamlined this paragraph.

> ----
>
> Page 14:
>
> I was a bit disturbed by the explanation that "the same wire may
> hold two different values", because the mental model offered by
> local `(signal S p)` scoping is that alpha-equivalence is fine, and
> in this example shadowing happens as it should. For a non-Esterel
> audience, the constant ambivalence between the "signals are
> non-shadowable wire names" and "signals are alpha-renamable binders"
> does not help comprehension. Maybe it would be possible to omit the
> "wire" view from the paper (or at least not mention it so often for
> intuitions) to avoid this somewhat parasitic concern.
>
> Note: it is unreasonable to show and try to explain this example
> before mentioning and precisely defining the transition to the next
> instant!

We have rewritten the section (now numbered 3.3) to try to explain
this issue better.

> ----
>
> The importance of the CB judgment was a bit lost on me. The rules
> for `loop`, `par` and `seq` are useful/interesting, the rest is very
> noisy, and I found that it distracts a bit from other, more
> interesting parts of your work (the reduction, evaluation, standard
> reduction).
>
> As far as I can tell, this judgment does *not* prevent/reject the
> weird loop example
>
>    (loop (signal SZ (seq pause (emit SZ))))
>
> so I don't really understand why the loop example was there in the
> first place. (I thought it was there to justify the judgment.)

We revised this section (also 3.3) of the paper. Our expectation is
that this part of our calculus will be more interesting to people who
study the semantics of Esterel, since other approaches handle the
problems of reincarnation and schizophrenia in different ways than we
do.

> ----
>
> Page 17:
>
> > The central result of this paper is that Eval is a function
>
> By "function" we usually mean "total function". I cannot tell from
> the theorem formulation if `Eval(p, Theta)` indeed is defined (in
> your mechanization?) a function and `= S_1` is a standard equality
> predicate, or you are referring to the `Eval(p, Theta) = S` judgment
> of the previous page and only state determinism, so Eval can be seen
> as a partial function. I think it is the latter, and I would rather
> use a clearly-not-equality relation symbol to avoid confusion:
> `Eval(p, Theta) is S` for example.
>

We improved the discussion of Eval's definition to clarify along the
lines suggested here.

> ----
>
> > non-constructive programs reduce stuck terms
>
> reduce to stuck terms

Fixed.

> ----
>
> Page 19:
>
>
> Theorem 8.3 is more clearly useful if one also establishes a
> monotonicity property
>
>    Can(Theta+{S->known}, p) \subseteq Can(Theta+{S->unknown})
>
> which I think you could state in the figure as well.
>
>
> I don't understand the formulation of Theorem 8.6, don't the hypotheses imply that
>
>    (signal S (present p_1 p2)) =e (signal S p2)
>
> so why does the more complex left-hand-side show up in this theorem
> statement?

We removed the present form to make this example more focused.

>
> Comment @A1 by Reviewer D
> ---------------------------------------------------------------------------
>
> > We are not getting how this [monotonicity] property benefits
> > Theorem 8.3 though. Could you elaborate?
>
> Monotonicity tells us that the conditions on the theorem's application,
>
>     S âˆ‰ (Can p { S â†¦ unknown }).S
>     S âˆ‰ (Can q { S â†¦ unknown }).S
>
> are the strongest for any choice of signal value for `S`: if `S` is
> not in `Can p (S |-> known)` for some `known`, then it is also not
> in `(Can p { S â†¦ unknown }).S`.
>
>
> In other words, your conditions are equivalent to the maybe more
> natural
>
>   forall status, S âˆ‰ (Can p { S â†¦ status }).S
>
> (Thinking about it, "useful" was not the right term.)

Thanks for the clarification. We agree and have fixed it.
